{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttTzJgjrEMvr"
      },
      "source": [
        "**Lab 3** for the course of *Selected Topics in Music and Acoustic Engineering* :\n",
        "\n",
        "***Machine Learning for Audio and Acoustic Engineering***\n",
        "---\n",
        "\n",
        "# **Before you start**\n",
        "\n",
        "*   Go to \"*File*\" --> \"*Save a copy in Drive*\"\n",
        "*   Open that copy (might open automatically)\n",
        "*   Then continue below\n",
        "\n",
        "# **Lab 3: Neural Networks**\n",
        "\n",
        "In this lab we will start to work with deep learning models. We will begin by looking at simple examples with synthetically generated data. Then, you will move to a more challenging and realistic problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SS1AeZyaoFa"
      },
      "source": [
        "### **Exercise 1**: Approximating Synthetic Data\n",
        "\n",
        "Execute the following lines for create a synthetically generated dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DPiW53wcsA3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "plt.style.use(\"seaborn-v0_8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk4nKhoxKOcl"
      },
      "outputs": [],
      "source": [
        "def gen_data(size, a, b):\n",
        "  x = np.random.rand(size,1)-0.5\n",
        "  y = a*x + b\n",
        "  y = y*(x>0)\n",
        "  y = y + 0.2*(np.random.randn(*x.shape))\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "HozkhnD9K0Bq",
        "outputId": "581caf42-2d58-484c-c807-3085acd67bea"
      },
      "outputs": [],
      "source": [
        "# Create data and plot\n",
        "Xdata, Ydata = gen_data(1000, 2, 1)\n",
        "plt.scatter(Xdata,Ydata);\n",
        "plt.xlabel('x');\n",
        "plt.ylabel('y');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo5tDSP4L7Rv"
      },
      "source": [
        "Describe the function underlying the model used to generate the data. Complete the symbols \"?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BGcZsdqMHRS"
      },
      "source": [
        "\\begin{equation}\n",
        "  y(x)=\\begin{cases}\n",
        "    ? *x + 1 + ? *  \\mathcal{N}(0, 1) & \\text{if } x >0 \\text{ ,where } x=\\mathcal{U}(0, 1) - ?\\\\\n",
        "     ? *  \\mathcal{N}(0, 1), & \\text{otherwise}.\n",
        "  \\end{cases}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV7PlkQ-SBKO"
      },
      "source": [
        "### **Exercise 2**: Create a MLP neural network model using Keras\n",
        "\n",
        "Create the following fully-connected feedforward network using Keras' sequential model. Use:\n",
        "\n",
        "| Layer | Type  | Units | Activation | Description                                                  |\n",
        "|-------|-------|-------|------------|--------------------------------------------------------------|\n",
        "| 1     | Dense | 5     | ReLU       | First hidden layer with 5 neurons, applies non-linearity     |\n",
        "| 2     | Dense | 5     | ReLU       | Second hidden layer, also with 5 neurons                     |\n",
        "| 3     | Dense | 1     | Linear     | Output layer, returns a single continuous value (regression) |\n",
        "\n",
        "Show the model's summary.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1UJwycQXQG8kkF0N8CmDW-ED-hY-Uck5o)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z5HTtnuSByR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvzcGPwbqM5r"
      },
      "source": [
        "How many parameters has the model?  (Hint: use the function model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UN8jPbJccS9",
        "outputId": "84a2cc55-3896-4355-d035-d71dbe1114b2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHb5qk0rrC9E"
      },
      "source": [
        "Compile the model and train it on Xdata using MSE as the loss function and SGD optimizer with learning rate 0.01. Train the model until reaching 300 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2nONgpTp_b-"
      },
      "outputs": [],
      "source": [
        "# model.compile(....)\n",
        "# history = model.fit(Xdata, Ydata, epochs=...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjncDBO-kZd7"
      },
      "source": [
        "Plot the training history of the network, showing the evolution of the training loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "Ux8hUvjbkfNW",
        "outputId": "b50cb042-d56a-4739-83fb-e1b04fad2b25"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTkdiKMVrvw1"
      },
      "source": [
        "Which is the minimum loss achieved by the model? At which epoch achieved that loss value?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6sFhYkur1cb",
        "outputId": "66d17d4b-7d61-4ab1-df3a-c0dda302ebfc"
      },
      "outputs": [],
      "source": [
        "# ...\n",
        "\n",
        "print('Minumum Loss on the Training Set: ', min_loss , ' obtained at epoch: ' , ''.join(map(str, min_loss_index[0])) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jigHsY7vkhhE"
      },
      "source": [
        "Plot the true training data together with the approximated data using the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "PXKQSnZYkuTg",
        "outputId": "c75cdc49-4b17-4c3c-8723-9581e7a47305"
      },
      "outputs": [],
      "source": [
        "# ...\n",
        "\n",
        "# plt.scatter(Xdata,Ydata)\n",
        "# plt.scatter(Xdata,preds);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhX7Encgs9le"
      },
      "source": [
        "Now initialize the model again and fit it, but train it for 1000 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLDYqnjgk9q_"
      },
      "outputs": [],
      "source": [
        "# Define the Fully-connected MLP\n",
        "# ....\n",
        "\n",
        "# Compiling the model\n",
        "# ...\n",
        "\n",
        "# Training the model\n",
        "# history_1000 = model.fit(Xdata, Ydata, epochs=...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfuDH5V1uZkC"
      },
      "source": [
        "Plot the original data and the predicted data. What are the differences observed with respect to the case before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "KWYLvnHVI5hg",
        "outputId": "c27bced6-50bd-4483-c6d1-b22374cfb2a5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlyWmPQuuVED"
      },
      "source": [
        "What is the best loss achieved in this case?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo6jqbmxulIf",
        "outputId": "605a01c2-4154-443e-b0dd-6eff7137735c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbc1V54S0gVk"
      },
      "source": [
        "### **Exercise 3**: Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpjIXg5O8X2R"
      },
      "source": [
        "Generate synthetically two bivariate Gaussian vectors (see np.random.multivariate_normal), each one with 1000 samples:\n",
        "\n",
        "*   Xdata0, with mean [-1,-1] and covariance [[4,0],[0,4]]\n",
        "*   Xdata1, with mean [1,1] and covariance [[3,0],[0,3]]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8jSWsGr0nCR",
        "outputId": "dc2c946e-25eb-435e-9d12-6baeda316c57"
      },
      "outputs": [],
      "source": [
        "#Bivariate Gaussian\n",
        "mean0 = [-1, -1]\n",
        "cov0 = [[4, 0], [0, 4]]\n",
        "\n",
        "mean1 = [1, 1]\n",
        "cov1 = [[3, 0], [0, 3]]\n",
        "\n",
        "# Xdata0 = ...\n",
        "# Xdata1 = ...\n",
        "\n",
        "# print(Xdata0.shape, Xdata1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expected output:\n",
        "```\n",
        "(1000, 2) (1000, 2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haEnI1qx8uj6"
      },
      "source": [
        "From the above Gaussian vectors, stack them to generate a feature data matrix Xdatac with shape (2000,2) and the corresponding label vector Ydatac with zeros and ones of shape (2000,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KoN2GtK2-Zh",
        "outputId": "9fa9fff3-400b-4341-f551-a0a28ccd25bb"
      },
      "outputs": [],
      "source": [
        "#Features\n",
        "# Xdatac = ...\n",
        "# Xdatac.shape\n",
        "\n",
        "#Labels\n",
        "labels0 = np.zeros(Xdata0.shape[0])\n",
        "labels1 = np.ones(Xdata1.shape[0])\n",
        "labels_gt = np.concatenate((labels0,labels1),axis=0).T\n",
        "\n",
        "# print(Xdatac.shape, labels_gt.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expected output:\n",
        "```\n",
        "(2000, 2) (2000, 2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcSi4_QD9uo8"
      },
      "source": [
        "Create a scatterplot of the two classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "7pAtI3Wv1e-z",
        "outputId": "c834033d-5100-42bf-c896-d28ef84ef54c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr3p9clN90ca"
      },
      "source": [
        "Divide the data Xdatac into a training partition and validation partition using \"train_test_split\" from sklearn. Use 30% of your data for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLZ2ZEiz44Jl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# X_train, X_valid, y_train, y_valid = train_test_split(....)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTNAI2pf-CA3"
      },
      "source": [
        "Create a model identical to the one of Exercise 2 but use sigmoid activation in the output layer. You need also now to specify that the input has two values.\n",
        "\n",
        "Train the model on the training partion. Select as loss function \"binary_crossentropy\" and monitor the training accuracy using metrics=[\"accuracy\"]. Use also the validation partition to track the validation accuracy at each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzfZleij2EhT"
      },
      "outputs": [],
      "source": [
        "# Define the Fully-connected MLP\n",
        "# ...\n",
        "\n",
        "# Compiling the model\n",
        "# ...\n",
        "\n",
        "# Training the model\n",
        "# history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btspjp3D-eac"
      },
      "source": [
        "Plot the training history showing the training accuracy and validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "xpH3zBSlEZ9b",
        "outputId": "0c2e4af9-c8c7-46ef-fcb7-c836f33acc89"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbbl3shiFGzQ"
      },
      "source": [
        "Predict over the training data and create a scatter plot showing the predicted class for each data example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRPLh-Rt6yO-",
        "outputId": "6dfb8b5a-6e6a-452d-9f51-16c2234b6675"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scatter the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "HnV7HsYp063S",
        "outputId": "f90fd098-25c1-45f4-c083-1b1cbe0dda81"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,13))\n",
        "plt.scatter(X_train[preds<0.5,0], X_train[preds<0.5,1], c='b')\n",
        "plt.scatter(X_train[preds>0.5,0], X_train[preds>0.5,1], c='r')\n",
        "plt.title('Scatter plot')\n",
        "plt.legend(('class 0','class 1'));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPVQhBWDNPVn"
      },
      "source": [
        "### **Exercise 4**: Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXST9LjNNfD7"
      },
      "source": [
        "Follow the same steps in Lab 2 to download the ESC-50 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KczAaxBoctON"
      },
      "outputs": [],
      "source": [
        "# !wget https://github.com/karolpiczak/ESC-50/archive/master.zip\n",
        "# !unzip master.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a list of the files corresponding to the 10 first classes. Those files will form our dataset (400 signals)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fn_csv = 'ESC-50-master/meta/esc50.csv'\n",
        "\n",
        "files = []  # File list\n",
        "labels = []  # Class list\n",
        "\n",
        "# ...\n",
        "\n",
        "print(f'Lengths: esc5_X: {len(files)}, esc5_y: {len(labels)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expected output:\n",
        "\n",
        "``` Lengths: esc5_X: 400, esc5_y: 400 ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert the labels to class indexes (rank 1) - e.g. 0,1,2,....,9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# labels = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJA7vLSnqz8D"
      },
      "source": [
        "Create a list storing the signals from all the files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTbcefHZOtuv"
      },
      "outputs": [],
      "source": [
        "# signals = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-qETpKXs1-V"
      },
      "source": [
        "For each signal in the list, compute the melspectrogram with librosa using default parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0UIgT1FPKvF"
      },
      "outputs": [],
      "source": [
        "mel_spegrams = []\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEoD1sJXOkNB"
      },
      "source": [
        "Convert the list to a numpy array called Xdata. You should end up with an array of shape (400, 128, 216). What do these numbers mean?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TudXqZSTtQ9m",
        "outputId": "5cf54b8b-8aaa-4ac9-84ab-a2346be183bb"
      },
      "outputs": [],
      "source": [
        "Xdata = np.asarray(mel_spegrams)\n",
        "Xdata.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expected output:\n",
        "\n",
        "```(400, 128, 216)```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrdc1A35c-Ic"
      },
      "source": [
        "ANSWER THE QUESTION HERE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs-V2zeXt5aD"
      },
      "source": [
        "### **Exercise 5**: MLP Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk4lkgdjt9ll"
      },
      "source": [
        "Let's try now to classify the audio files by using the computed mel spectrogram data. First, flatten each spectrogram into a one-dimensional array, so that you end up with a new array Xdata_f of shape (400, 27648). You can do that by using the function reshape from numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTKsOdovuPAr",
        "outputId": "0e0f161b-bb76-4349-92e7-ddb054717cbf"
      },
      "outputs": [],
      "source": [
        "# Xdata_f = ...\n",
        "# print(Xdata_f.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expected output:\n",
        "```\n",
        "(400, 27648)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5qGcSiavXGr"
      },
      "source": [
        "Let's first use the sklearn StandardScaler function to scale the data (save the output in Xdata_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scaler = ...\n",
        "# Xdata_s = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PWqGV6IvHdX"
      },
      "source": [
        "Create a test and validation split with 20% of the samples. Call the splits X_train, y_train, X_val, y_val."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_2E2YpYvGbV"
      },
      "outputs": [],
      "source": [
        "# X_train, X_val, y_train, y_val = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJDUp3y9xSiu"
      },
      "source": [
        "Now, create a MLP-based network for classifying these audios. You can use the same layer structure as in the previous examples, but remember to adapt the output layer so that its size is equal to the number of classes and apply 'softmax' activation. You can also try to increase the number of neurons in the hidden layers.\n",
        "\n",
        "Proposed architecture:\n",
        "\n",
        "| Layer | Type  | Units | Activation | Output Shape           | Description                                  |\n",
        "|-------|-------|-------|------------|-------------------------|----------------------------------------------|\n",
        "| Input | Input | -     | -          | (None, shape_size)      | Input layer with `shape_size` features       |\n",
        "| 1     | Dense | 16    | ReLU       | (None, 16)              | First hidden layer with 16 neurons           |\n",
        "| 2     | Dense | 16    | ReLU       | (None, 16)              | Second hidden layer with 16 neurons          |\n",
        "| 3     | Dense | 10    | Softmax    | (None, 10)              | Output layer for 10-class classification     |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4UFLOjluX6F",
        "outputId": "a79fe55c-e053-442b-cc81-35c697c3a007"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db9NRrs42OxS"
      },
      "source": [
        "Fit the model using \"sparse_categorical_crossentropy\" as loss function. Probably your first attempts will overfit.\n",
        "\n",
        "Try different strategies to prevent overfitting:\n",
        "\n",
        "*   Dropout\n",
        "*   Regularization\n",
        "*   Reduce number of neurons/layers\n",
        "\n",
        "What is the best accuracy you could get with a fully-based MLP network?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hJJaPOFVTkA"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "\n",
        "# Training the model\n",
        "# history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=300)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Which is the minimum loss achieved by the model? At which epoch achieved that loss value?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFwVNJcyXQac",
        "outputId": "5f0b5a6e-8032-4edf-bdc5-e476a8a56179"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the training history of the network, showing the evolution of the training/validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "9Su-VE93ZsjY",
        "outputId": "2a6c90c0-2129-4cad-b6ec-73e318e6de4f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg5Tkp5f6Grc"
      },
      "source": [
        "* REPEAT EXPERIMENTS USING THE AFOREMENTIONED TECHNIQUES TO PREVENT OVERFITTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r950zGgp68Ef"
      },
      "source": [
        "### **Exercise 6**: CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NblxveeIr_ZJ"
      },
      "source": [
        "Create training and validation partitions from Xdata. Remember that Xdata stores has size (400, 128, 216), storing 400 Mel spectrograms of sie (128,216). Name the partitions X_train, X_test, y_train and y_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b2_qbdS92gV"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(..., test_size=0.2)\n",
        "# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcb0EgHItIiv"
      },
      "source": [
        "Scale each spectrogram by substracting its mean and dividing by its standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOVECx1b_Pwd",
        "outputId": "aa87982e-c81d-468f-bb55-046f689b4042"
      },
      "outputs": [],
      "source": [
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "X_train_s = []\n",
        "X_test_s = []\n",
        "\n",
        "# ...\n",
        "\n",
        "X_train_s = np.asarray(X_train_s)\n",
        "X_test_s = np.asarray(X_test_s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGBbfRgLtgf4"
      },
      "source": [
        "Create a convolutional neural network model. Remember to adapt the input shape of the first layer to the new input. \n",
        "\n",
        "You can start with a model like the next one. Remember to include regularization strategies like dropout layers.\n",
        "\n",
        "| Layer | Type        | Filters/Units | Kernel/Pool Size | Activation | Output Shape        | Description                                  |\n",
        "|-------|-------------|----------------|------------------|------------|---------------------|----------------------------------------------|\n",
        "| Input | Input        | -              | -                | -          | (None, H, W, C)      | Input shape from `X_train_sx.shape[1:]`      |\n",
        "| 1     | Conv2D       | 16             | (3, 3)           | ReLU       | (None, H-2, W-2, 16) | First convolutional layer                    |\n",
        "| 2     | MaxPooling2D | -              | (3, 3), stride 3 | -          | (None, H//3, W//3, 16) | Downsamples feature maps                     |\n",
        "| 3     | Conv2D       | 16             | (3, 3)           | ReLU       | (None, ..., ..., 16) | Second convolutional layer                   |\n",
        "| 4     | MaxPooling2D | -              | (2, 2), stride 2 | -          | (None, ..., ..., 16) | Second pooling layer                         |\n",
        "| 5     | Conv2D       | 32             | (2, 2)           | ReLU       | (None, ..., ..., 32) | Third convolutional layer                    |\n",
        "| 6     | Flatten      | -              | -                | -          | (None, N)            | Flattens 2D features to 1D vector            |\n",
        "| 7     | Dense        | 32             | -                | ReLU       | (None, 32)           | Fully connected hidden layer                 |\n",
        "| 8     | Dropout      | -              | -                | -          | (None, 32)           | Dropout for regularization (rate=0.1)        |\n",
        "| 9     | Dense        | 10             | -                | Softmax    | (None, 10)           | Output layer for 10-class classification     |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onOmkSv6uaE3"
      },
      "outputs": [],
      "source": [
        "# expanding X_train_s and X_test_s to fit conv2d\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZbA_3Tz7MOg",
        "outputId": "4714018f-9863-45fe-ae2b-dda784574d3f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRQeR1uw12dL"
      },
      "source": [
        "Fit the model and try to improve the results obtained with the MLP model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQpBsIbjAmIQ"
      },
      "outputs": [],
      "source": [
        "#compile the model\n",
        "# ...\n",
        "\n",
        "#fit the model\n",
        "# history = model.fit(X_train_sx, y_train, validation_data=(X_test_sx, y_test), batch_size=32, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ScY9s12AC2"
      },
      "source": [
        "Plot the training history (train/val loss/accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "YZo46PhVAsPg",
        "outputId": "f09533d4-8804-416b-efa3-d6d13f01da0f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Which is the minimum loss achieved by the model? At which epoch achieved that loss value?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QTeJ47F6B5i",
        "outputId": "fe4779e1-0f73-493e-b6d3-65b7a5a90f82"
      },
      "outputs": [],
      "source": [
        "# ...\n",
        "\n",
        "# print('Minimum Loss on the Validation Set: ', min_val_loss ,' obtained at epoch: ' , ''.join(map(str, min_val_loss_index[0])), '  with an Accuracy of: ', val_accuracy_history[int(min_val_loss_index[0].item())] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrYt8YSo55L0"
      },
      "source": [
        "Tune your model and try to achieve an accuracy above 60%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U5OdJEFurHt",
        "outputId": "3a513939-1ae8-4b66-f95e-a24b5dab7f6c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Student_Lab_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
